{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, '../../framework')\n",
    "from racetrack import *\n",
    "rt = RACETrack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from jsonpath_ng import jsonpath, parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scanForward() - finds the next unescaped version of c in x starting at i\n",
    "def scanForward(x, i, c):\n",
    "    in_escape = False\n",
    "    while i < len(x):\n",
    "        if   x[i] == '\\\\' and in_escape == False: in_escape = True\n",
    "        else:\n",
    "            if x[i] == c and in_escape == False: return i\n",
    "            in_escape = False\n",
    "        i += 1\n",
    "    return None\n",
    "\n",
    "# literalize() - converts any single or double quoted strings into unique literal names\n",
    "def literalize(x):\n",
    "    l, lu = [], {}\n",
    "    i = 0\n",
    "    while i < len(x):\n",
    "        c = x[i]\n",
    "        if   c == \"'\":\n",
    "            j = scanForward(x, i+1, \"'\")\n",
    "            if j is None: raise Exception(f'OntologyForViz.literalize() - unterminated string literal \"{x}\"')\n",
    "            _literal_name_ = f'__lit{len(lu.keys())}__'\n",
    "            lu[_literal_name_] = x[i+1:j]\n",
    "            l.append(_literal_name_)\n",
    "            i = j + 1\n",
    "        elif c == '\"':\n",
    "            j = scanForward(x, i+1, '\"')\n",
    "            if j is None: raise Exception(f'OntologyForViz.literalize() - unterminated string literal \"{x}\"')\n",
    "            _literal_name_ = f'__lit{len(lu.keys())}__'\n",
    "            lu[_literal_name_] = x[i+1:j]\n",
    "            l.append(_literal_name_)\n",
    "            i = j + 1\n",
    "        else:\n",
    "            l.append(c)\n",
    "            i += 1\n",
    "    return ''.join(l), lu\n",
    "\n",
    "# findClosingParen() - find the next closing paren taking other open/closes into consideration\n",
    "# ... requires that literals were taken care of... [see literalize function]\n",
    "def findClosingParen(s, i):\n",
    "    stack = 0\n",
    "    while i < len(s):\n",
    "        if   s[i] == '(':               stack += 1\n",
    "        elif s[i] == ')' and stack > 0: stack -= 1\n",
    "        elif s[i] == ')':               return i\n",
    "        i += 1\n",
    "    raise Exception(f'OntologyForViz.findClosingParen() - no closing paren found for \"{s}\"')\n",
    "\n",
    "# tokenizeParameters() - create a token list of function parameters\n",
    "# ... requires that literals were taken care of... [see literalize function]\n",
    "def tokenizeParameters(x):\n",
    "    r = []\n",
    "    while ',' in x or '(' in x:\n",
    "        if   ',' in x and '(' in x: # both... process the one that occurs first\n",
    "            i = x.index(',')\n",
    "            j = x.index('(')\n",
    "            if i < j:\n",
    "                r.append(x[:i])\n",
    "                x = x[i+1:]\n",
    "            else:\n",
    "                k = findClosingParen(x,j+1)\n",
    "                r.append(x[:k+1].strip())\n",
    "                x = x[k+1:]\n",
    "                if ',' in x: x = x[x.index(',')+1:] # if there's another comma, consume it\n",
    "        elif ',' in x: # just literals from here on out...\n",
    "            r.append(x[:x.index(',')].strip())\n",
    "            x = x[x.index(',')+1:]\n",
    "        elif '(' in x: # just one function call from here on out...\n",
    "            i = x.index('(')\n",
    "            j = findClosingParen(x,i+1)\n",
    "            r.append(x[:j+1].strip())\n",
    "            x = x[j+1:]\n",
    "            if ',' in x: x = x[x.index(',')+1:] # if there's another comma, consume it\n",
    "    x = x.strip()\n",
    "    if len(x) > 0:\n",
    "        r.append(x)\n",
    "    return r\n",
    "\n",
    "# parseTree() - create a parse tree representation of a ontology node description\n",
    "def parseTree(x, node_value=None, node_children=None, node_name=None, lit_lu=None):\n",
    "    if node_value is None:\n",
    "        node_value = {}\n",
    "        node_children = {}\n",
    "        node_name = 'root'\n",
    "\n",
    "    if lit_lu is None:\n",
    "        x, lit_lu = literalize(x)\n",
    "    if '(' in x:\n",
    "        i          = x.index('(')\n",
    "        j          = findClosingParen(x, i+1)\n",
    "        fname      = x[0:i].strip()\n",
    "        parms      = tokenizeParameters(x[i+1:j])\n",
    "        node_value   [node_name] = lit_lu[fname] if fname in lit_lu else fname\n",
    "        node_children[node_name] = []    # functions have children... even if it's an empty list of children\n",
    "        for child_i in range(len(parms)):\n",
    "            child_name = f'{node_name}.{child_i}'\n",
    "            node_children[node_name].append(child_name)\n",
    "            parseTree(parms[child_i], node_value, node_children, child_name, lit_lu)\n",
    "    else:\n",
    "        x                        = x.strip()\n",
    "        node_value   [node_name] = lit_lu[x] if x in lit_lu else x\n",
    "        node_children[node_name] = None # literals have no children\n",
    "    return node_value, node_children\n",
    "\n",
    "# solveParseTree() - evaluate a parse tree\n",
    "def solveParseTree(values, children, filled, i, node=None):\n",
    "    if node is None: node = 'root'\n",
    "    if   children[node] is None and isJsonPath(values[node]):\n",
    "        return filled[values[node]][i]  # jsonpath filled in value from the json\n",
    "    elif children[node] is None:\n",
    "        return values[node]             # constant / literal\n",
    "    else:\n",
    "        parms = [solveParseTree(values, children, filled, i, x) for x in children[node]]\n",
    "        return eval(f'{values[node]}(*parms)')\n",
    "\n",
    "# upToStar() - upto the cth '[*]'\n",
    "def upToStar(x, c):\n",
    "    i = 0\n",
    "    while c > 0:\n",
    "        j = x.index('[*]', i)\n",
    "        i = j + 3\n",
    "        c -= 1\n",
    "    return x[:i]\n",
    "\n",
    "# fillStars() - fill the the stars in the specified order\n",
    "def fillStars(x, i, j=None, k=None):\n",
    "    _index_ = x.index('[*]')\n",
    "    x = x[:_index_] + f'[{i}]' + x[_index_+3:]\n",
    "    if j is not None and '[*]' in x:\n",
    "        _index_ = x.index('[*]')\n",
    "        x = x[:_index_] + f'[{j}]' + x[_index_+3:]\n",
    "    if k is not None and '[*]' in x:\n",
    "        _index_ = x.index('[*]')\n",
    "        x = x[:_index_] + f'[{k}]' + x[_index_+3:]\n",
    "    return x\n",
    "\n",
    "# isJsonPath() - check if the string is a jsonpath\n",
    "def isJsonPath(_str_): \n",
    "    return _str_.startswith('$.') or _str_.startswith('$[')\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "class OntologyForViz(object):\n",
    "    # __init__() - prepare transform spec for use\n",
    "    def __init__(self, xform_spec):\n",
    "        self.xform_spec_lines = self.__substituteDefines__(xform_spec)\n",
    "        self.df_triples = pd.DataFrame()\n",
    "\n",
    "    # __substituteDefines__() - subsitute defines\n",
    "    def __substituteDefines__(self, _txt_):\n",
    "        lines     = _txt_.split('\\n')\n",
    "        subs      = {}\n",
    "        completes = []\n",
    "        for _line_ in lines:\n",
    "            tokens = _line_.split()\n",
    "            if len(tokens) >= 3 and tokens[1] == '=':\n",
    "                subs[tokens[0]] = ' '.join(tokens[2:])\n",
    "            else:\n",
    "                for r in subs:\n",
    "                    if r in _line_:\n",
    "                        _line_ = _line_.replace(r, subs[r])\n",
    "                if len(_line_) > 0:\n",
    "                    completes.append(_line_)\n",
    "        return completes\n",
    "\n",
    "    # __applyTemplate__() - apply templated line in the transform to the json representation\n",
    "    def __applyTemplate__(self, \n",
    "                          myjson,        # json representation\n",
    "                          s_values,      # subject parse tree values\n",
    "                          s_children,    # subject parse tree structure\n",
    "                          s_type,        # subject variable type\n",
    "                          s_uniq,        # is subject a unique entity?\n",
    "                          v_values,      # verb parse tree values\n",
    "                          v_children,    # verb parse tree structure\n",
    "                          o_values,      # object parse tree values\n",
    "                          o_children,    # object parse tree structure\n",
    "                          o_type,        # object type\n",
    "                          o_uniq):       # is object a unique entity?\n",
    "        # resolve the jsonpath values        \n",
    "        all_values  = set(s_values.values()) | set(v_values.values()) | set(o_values.values())\n",
    "\n",
    "        path_values, longest_by_star_path, filled = [], None, {}\n",
    "        for x in all_values:\n",
    "            filled[x] = []\n",
    "            if isJsonPath(x):\n",
    "                path_values.append(x)\n",
    "                if '*' in x:\n",
    "                    if   longest_by_star_path is None:\n",
    "                        longest_by_star_path = x\n",
    "                    elif longest_by_star_path.rindex('*') < x.rindex('*'):\n",
    "                        longest_by_star_path = x\n",
    "\n",
    "        # ensure that all jsonpath values are substrings of the longest star path\n",
    "        for x in path_values:\n",
    "            if '*' in x:\n",
    "                x_until_last_star = x[:x.rindex('*')+2] # get the close bracket too\n",
    "                if longest_by_star_path[:len(x_until_last_star)] != x_until_last_star:\n",
    "                    raise Exception(f'OntologyForViz.__applyTemplate__() - jsonpath are not subsets \"{x}\" vs \"{longest_by_star_path}\"')\n",
    "                \n",
    "        # fill in the json values into the filled dict\n",
    "        if    longest_by_star_path is None:\n",
    "            raise('OntologyForViz.__applyTemplate__() - no meaningful jsonpath(s) found')\n",
    "        else:\n",
    "            star_count = longest_by_star_path.count('[*]')\n",
    "            if star_count   == 1:\n",
    "                for i in range(len(parse(upToStar(longest_by_star_path, 1)).find(myjson))):\n",
    "                    for v in filled.keys():\n",
    "                        if isJsonPath(v):\n",
    "                            _matches_ = parse(fillStars(v, i)).find(myjson)\n",
    "                            if len(_matches_) == 1: filled[v].append(_matches_[0].value)\n",
    "                            else:                   filled[v].append(None)\n",
    "                        else:\n",
    "                            filled[v].append(v)\n",
    "            elif star_count == 2:\n",
    "                for i in range(len(parse(upToStar(longest_by_star_path, 1)).find(myjson))):\n",
    "                    for j in range(len(parse(upToStar(fillStars(longest_by_star_path,i), 1)).find(myjson))):\n",
    "                        for v in filled.keys():\n",
    "                            if isJsonPath(v):\n",
    "                                _matches_ = parse(fillStars(v, i, j)).find(myjson)\n",
    "                                if len(_matches_) == 1: filled[v].append(_matches_[0].value)\n",
    "                                else:                   filled[v].append(None)\n",
    "                            else:\n",
    "                                filled[v].append(v)\n",
    "            elif star_count == 3:\n",
    "                for i in range(len(parse(upToStar(longest_by_star_path, 1)).find(myjson))):\n",
    "                    for j in range(len(parse(upToStar(fillStars(longest_by_star_path,i), 1)).find(myjson))):\n",
    "                        for k in range(len(parse(upToStar(fillStars(longest_by_star_path,i,j), 1)).find(myjson))):\n",
    "                            for v in filled.keys():\n",
    "                                if isJsonPath(v):\n",
    "                                    _matches_ = parse(fillStars(v, i, j, k)).find(myjson)\n",
    "                                    if len(_matches_) == 1: filled[v].append(_matches_[0].value)\n",
    "                                    else:                   filled[v].append(None)\n",
    "                                else:\n",
    "                                    filled[v].append(v)\n",
    "            else:\n",
    "                raise Exception(f'OntologyForViz.__applyTemplate__() - max of three stars supported -- {star_count} found')\n",
    "\n",
    "        # collapse the parse trees based on the filled values\n",
    "        # ... double check that they are the same length\n",
    "        l = None\n",
    "        for v in filled.keys():\n",
    "            if l is None: l = len(filled[v])\n",
    "            if len(filled[v]) != l: raise Exception(f'OntologyForViz.__applyTemplate__() - unequal number of values for {v}')\n",
    "        subjects, verbs, objects = [], [], []\n",
    "        for i in range(l):\n",
    "            _subject_ = solveParseTree(s_values, s_children, filled, i)\n",
    "            _verb_    = solveParseTree(v_values, v_children, filled, i)\n",
    "            _object_  = solveParseTree(o_values, o_children, filled, i)\n",
    "            subjects.append(_subject_), verbs.append(_verb_), objects.append(_object_)\n",
    "        _df_            = pd.DataFrame({'subject': subjects, 'verb': verbs, 'object': objects})\n",
    "        self.df_triples = pd.concat([_df_, self.df_triples], ignore_index=True)\n",
    "\n",
    "    # parse() - parse json into ontology via specification\n",
    "    def parse(self, j):\n",
    "        for l in self.xform_spec_lines:\n",
    "            svo = [x.strip() for x in l.split('---')]\n",
    "            if len(svo) == 3:\n",
    "                s, v, o = svo[0], svo[1], svo[2]\n",
    "\n",
    "                # Subject\n",
    "                s_uniq, o_uniq = False, False\n",
    "                if s.endswith('uniq'):\n",
    "                    s = s[:s.rindex('|')]\n",
    "                    s_uniq = True\n",
    "                s_type = s[s.rindex('|')+1:].strip()\n",
    "                s_node = s[:s.rindex('|')]\n",
    "                s_values, s_children = parseTree(s_node)\n",
    "\n",
    "                # Verb\n",
    "                v_values, v_children = parseTree(v)\n",
    "\n",
    "                # Object\n",
    "                if o.endswith('uniq'):\n",
    "                    o = o[:o.rindex('|')]\n",
    "                    o_uniq = True\n",
    "                o_type = o[o.rindex('|')+1:].strip()\n",
    "                o_node = o[:o.rindex('|')]\n",
    "                o_values, o_children = parseTree(o_node)\n",
    "\n",
    "                self.__applyTemplate__(j, s_values, s_children, s_type, s_uniq, \n",
    "                                          v_values, v_children, \n",
    "                                          o_values, o_children, o_type, o_uniq)\n",
    "            else:\n",
    "                raise Exception(f'OntologyForViz.parse() - line \"{l}\" does not have three parts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_json_txt_ = '''\n",
    "{\"id\":1,\n",
    " \"people\":[{\"first\":\"John\", \"last\":\"Smith\", \"age\":30, \"city\":\"nyc\",          \"state\":\"ny\", \"country\":\"us\"},\n",
    "           {\"first\":\"Joe\",  \"last\":\"Smith\", \"age\":35,                        \"state\":\"ny\", \"country\":\"us\"},\n",
    "           {\"first\":\"Mary\", \"last\":\"Jones\", \"age\":32, \"city\":\"philadelphia\", \"state\":\"pa\", \"country\":\"us\"}],\n",
    " \"total_people\":3\n",
    "}'''\n",
    "_json_simple_  = json.loads(_json_txt_)\n",
    "_xform_simple_ = '''\n",
    "'$.people[*].last' | xsd:string --- \"hasAge\" --- '$.people[*].age' | xsd:integer\n",
    "'''\n",
    "ofv = OntologyForViz(_xform_simple_)\n",
    "ofv.parse(_json_simple_)\n",
    "ofv.df_triples.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_base_ = '../../../data/kaggle_imdb_600k/international-movies-json/'\n",
    "_files_ = os.listdir(_base_)\n",
    "for _file_ in _files_:\n",
    "    _txt_  = open(_base_ + _file_).read()\n",
    "    _json_ = json.loads(_txt_)\n",
    "\n",
    "# Length\n",
    "print(len(parse('$[*]').find(_json_)))\n",
    "# Examples\n",
    "jsp_expr = parse('$[*].name')\n",
    "jsp_expr = parse('$[*].cast.[*].name') # but note that it doesn't distinguish the movie id\n",
    "jsp_expr = parse('$..director.name')\n",
    "jsp_expr = parse('$..name')\n",
    "jsp_expr = parse('$..genre[*]')\n",
    "[match.value for match in jsp_expr.find(_json_)][:3]\n",
    "\n",
    "# Example within transform processing\n",
    "def returnsSame(x):\n",
    "    return x\n",
    "\n",
    "# Example Transform Map\n",
    "# ... maybe add \"@@@\" for grouping the triples together ... and then \"^^^\" for sourcing?\n",
    "_xform_map_ = '''\n",
    "__id__              = returnsSame('$[*]._id') | xsd:string | uniq\n",
    "__director__        = '$[*].director.name_id' | xsd:string | uniq\n",
    "__castmember__      = '$[*].cast.[*].name_id' | xsd:string | uniq\n",
    "__id__              --- \"hasTitle\"       --- '$[*].name'          | xsd:string\n",
    "__id__              --- \"yearReleased\"   --- '$[*].year'          | xsd:date\n",
    "__id__              --- \"runTime\"        --- '$[*].runtime'       | xsd:duration\n",
    "__id__              --- \"hasGenre\"       --- '$[*].genre[*]'      | xsd.string\n",
    "__id__              --- \"ratingValue\"    --- '$[*].ratingValue'   | xsd:float\n",
    "__id__              --- \"summary\"        --- '$[*].summary_text'  | xsd:string\n",
    "__director__        --- \"directedMovie\"  --- __id__\n",
    "__director__        --- \"hasName\"        --- '$[*].director.name' | xsd:string\n",
    "__castmember__      --- \"castMemberOf\"   --- __id__\n",
    "__castmember__      --- \"hasName\"        --- '$[*].cast.[*].name' | xsd:string\n",
    "'''\n",
    "\n",
    "ofv = OntologyForViz(_xform_map_)\n",
    "ofv.parse(_json_)\n",
    "ofv.df_triples.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
