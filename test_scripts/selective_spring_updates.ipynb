{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff931a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Tests the ability to use springs layout selectively on subgraphs\n",
    "# ... so, if you keep the placement of the nodes from an initial all-nodes layout\n",
    "# ... then you can update the placement of a subset of the nodes\n",
    "#\n",
    "# However... because that's not the only transform done to make this all work\n",
    "# (think about the treemap component placement), then there's always a scaling factor\n",
    "# involved... and that breaks the ability to apply the spring layout to a subset of \n",
    "# nodes...\n",
    "#\n",
    "\n",
    "import polars   as pl\n",
    "import networkx as nx\n",
    "import random\n",
    "import copy\n",
    "import rtsvg\n",
    "import linknode_graph_patterns\n",
    "from rtsvg.polars_spring_layout import PolarsSpringLayout\n",
    "rt   = rtsvg.RACETrack()\n",
    "'''\n",
    "g    = linknode_graph_patterns.LinkNodeGraphPatterns().__pattern_mesh__()\n",
    "_lu_ = {'fm':[], 'to':[]}\n",
    "for n in g.nodes():\n",
    "    for nbor in g.neighbors(n): _lu_['fm'].append(n), _lu_['to'].append(nbor)\n",
    "df        = pl.DataFrame(_lu_)\n",
    "_to_fix_  = {'node_0_5', 'node_7_4', 'node_8_6', 'node_5_8'}\n",
    "'''\n",
    "\n",
    "_base_network_ = '0'\n",
    "_base_dir_     = '../../data/stanford/facebook/'\n",
    "_layout_file_  = _base_dir_ + _base_network_ + '.layout.parquet'\n",
    "_edges_ = open(_base_dir_ + _base_network_ + '.edges', 'rt').read()\n",
    "_lu_ = {'fm':[], 'to':[]}\n",
    "for _edge_ in _edges_.split('\\n'):\n",
    "    if _edge_ == '': continue\n",
    "    _lu_['fm'].append(_edge_.split(' ')[0])\n",
    "    _lu_['to'].append(_edge_.split(' ')[1])\n",
    "df        = pl.DataFrame(_lu_)\n",
    "_relates_ = [('fm','to')]\n",
    "g         = rt.createNetworkXGraph(df, _relates_)\n",
    "_to_fix_  = {'110', '193', '201', '245', '259', '264', '61', '8', '91'}\n",
    "\n",
    "_relates_ = [('fm','to')]\n",
    "_colors_  = {n:'red' for n in _to_fix_}\n",
    "_psl_     = PolarsSpringLayout(g)\n",
    "pos       = _psl_.results()\n",
    "new_pos   = copy.deepcopy(pos)\n",
    "for n in _to_fix_: new_pos[n] = (new_pos[n][0] + 100*(random.random()-0.5), new_pos[n][1] + 100*(random.random()-0.5))\n",
    "new_new_pos = copy.deepcopy(new_pos)\n",
    "new_new_pos = PolarsSpringLayout(g, pos=new_new_pos, static_nodes=set(g.nodes()) - _to_fix_, normalize_coordinates=True).results()\n",
    "params      = {'w':384, 'h':384, 'node_color':_colors_}\n",
    "rt.tile([rt.link(df, _relates_, pos,         **params),\n",
    "         rt.link(df, _relates_, new_pos,     **params),\n",
    "         rt.link(df, _relates_, new_new_pos, **params)], spacer=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acdfe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# So... maybe it's possible to rescale the graph based on the expected distances\n",
    "# ... in this case (mesh graph), all edges should be 1.0 ... so... how to take\n",
    "# ... a random set of positions & then rescale them?\n",
    "#\n",
    "_d_sum_, _d_samples_, _rms_sum_ = 0.0, 0, 0.0\n",
    "for n in g.nodes():\n",
    "    for nbor in g.neighbors(n):\n",
    "        _w_                  =  g[n][nbor]['weight']\n",
    "        _xy_n_, _xy_nbor_    =  pos[n], pos[nbor]\n",
    "        _d_                  =  rt.segmentLength((_xy_n_, _xy_nbor_))\n",
    "        _w_diff_             =  _w_ - _d_\n",
    "        _rms_sum_            += _w_diff_**2\n",
    "        _d_sum_, _d_samples_ = _d_sum_ + _d_, _d_samples_ + 1\n",
    "print(_d_sum_, _d_samples_, _d_sum_ / _d_samples_) # 359.24853900508407 288 1.2473907604343197 -- example from the mesh graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219b4fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Grid Search Version of This Optimization\n",
    "#\n",
    "_lu_ = {'x_scale':[], 'y_scale':[], 'rms':[]}\n",
    "_inc_     = 0.05\n",
    "_x_scale_ = 0.5\n",
    "while _x_scale_ < 1.5:\n",
    "    _y_scale_ = 0.5\n",
    "    while _y_scale_ < 1.5:\n",
    "        _rms_ = _psl_.rootMeanSquareError(_x_scale_, _y_scale_)\n",
    "        _lu_['x_scale'].append(_x_scale_)\n",
    "        _lu_['y_scale'].append(_y_scale_)\n",
    "        _lu_['rms'].append(_rms_)\n",
    "        _y_scale_ += _inc_\n",
    "    _x_scale_ += _inc_\n",
    "\n",
    "rt.tile([rt.xy(pl.DataFrame(_lu_), x_field='x_scale', y_field='rms', line_groupby_field='y_scale', color_by='y_scale', dot_size=None),\n",
    "         rt.xy(pl.DataFrame(_lu_), x_field='y_scale', y_field='rms', line_groupby_field='x_scale', color_by='x_scale', dot_size=None)], spacer=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40090ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# From Google AI\n",
    "#\n",
    "import numpy as np\n",
    "\n",
    "def calculate_parabola_coefficients(p1, p2, p3):\n",
    "    \"\"\"\n",
    "    Calculates the coefficients (a, b, c) of a parabola y = ax^2 + bx + c\n",
    "    that passes through three given points.\n",
    "\n",
    "    Args:\n",
    "        p1 (tuple): The first point (x1, y1).\n",
    "        p2 (tuple): The second point (x2, y2).\n",
    "        p3 (tuple): The third point (x3, y3).\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the coefficients (a, b, c).\n",
    "               Returns None if the points are collinear or cannot form a unique parabola.\n",
    "    \"\"\"\n",
    "    x1, y1 = p1\n",
    "    x2, y2 = p2\n",
    "    x3, y3 = p3\n",
    "\n",
    "    # Construct the matrix A and vector B for the system of equations\n",
    "    # A * [a, b, c]^T = B\n",
    "    A = np.array([\n",
    "        [x1**2, x1, 1],\n",
    "        [x2**2, x2, 1],\n",
    "        [x3**2, x3, 1]\n",
    "    ])\n",
    "\n",
    "    B = np.array([y1, y2, y3])\n",
    "\n",
    "    try:\n",
    "        # Solve the system of equations for a, b, c\n",
    "        coefficients = np.linalg.solve(A, B)\n",
    "        return tuple(coefficients)\n",
    "    except np.linalg.LinAlgError:\n",
    "        # This error occurs if the matrix A is singular,\n",
    "        # which happens when the three points are collinear.\n",
    "        print(\"Error: The three points are collinear or cannot form a unique parabola.\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "point1 = (1, 2)\n",
    "point2 = (2, 1)\n",
    "point3 = (3, 4)\n",
    "\n",
    "a, b, c = calculate_parabola_coefficients(point1, point2, point3)\n",
    "\n",
    "if a is not None: print(f\"Parabola coefficients: a={a}, b={b}, c={c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388094e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_lu_ = {'x_scale':[], 'rms':[], 'group':[]}\n",
    "x_scale = 0.1\n",
    "while x_scale < 2.0:\n",
    "    rms = _psl_.rootMeanSquareError(x_scale, 1.0)\n",
    "    _lu_['x_scale'].append(x_scale), _lu_['rms'].append(rms), _lu_['group'].append('rms')\n",
    "    x_scale += 0.1\n",
    "\n",
    "for i in range(1,len(_lu_['rms'])-1):\n",
    "    if _lu_['rms'][i] < _lu_['rms'][i-1] and _lu_['rms'][i] < _lu_['rms'][i+1]:\n",
    "        print(f'Found! ({i=})')\n",
    "        p0 = (_lu_['x_scale'][i-1], _lu_['rms'][i-1])\n",
    "        p1 = (_lu_['x_scale'][i],   _lu_['rms'][i])\n",
    "        p2 = (_lu_['x_scale'][i+1], _lu_['rms'][i+1])\n",
    "\n",
    "_a_, _b_, _c_ = calculate_parabola_coefficients(p0, p1, p2) \n",
    "_a_, _b_, _c_ = float(a), float(b), float(c)\n",
    "\n",
    "if _a_ > 0.0: # opens upward...\n",
    "    x = -_b_ / 2 * _a_\n",
    "    y = _a_ * x**2 + _b_ * x + _c_ \n",
    "else: raise Exception('Parabola opens downward...')\n",
    "x,y\n",
    "\n",
    "_lu2_ = {'x_scale':[], 'rms':[], 'group':[]}\n",
    "x_scale = 0.1\n",
    "while x_scale < 2.0:\n",
    "    _lu2_['x_scale'].append(x_scale), _lu2_['rms'].append(_a_ * x_scale**2 + _b_ * x_scale + _c_), _lu2_['group'].append('formula')\n",
    "    x_scale += 0.1\n",
    "_df_ = pl.concat([pl.DataFrame(_lu_), pl.DataFrame(_lu2_)])\n",
    "rt.tile([rt.xy(_df_, x_field='x_scale', y_field='rms',     w=768, line_groupby_field=\"group\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6e644d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
