{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff931a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Tests the ability to use springs layout selectively on subgraphs\n",
    "# ... so, if you keep the placement of the nodes from an initial all-nodes layout\n",
    "# ... then you can update the placement of a subset of the nodes\n",
    "#\n",
    "# However... because that's not the only transform done to make this all work\n",
    "# (think about the treemap component placement), then there's always a scaling factor\n",
    "# involved... and that breaks the ability to apply the spring layout to a subset of \n",
    "# nodes...\n",
    "#\n",
    "\n",
    "import polars   as pl\n",
    "import networkx as nx\n",
    "import random\n",
    "import copy\n",
    "import rtsvg\n",
    "import linknode_graph_patterns\n",
    "from rtsvg.polars_spring_layout import PolarsSpringLayout\n",
    "rt   = rtsvg.RACETrack()\n",
    "\n",
    "g    = linknode_graph_patterns.LinkNodeGraphPatterns().__pattern_mesh__()\n",
    "_lu_ = {'fm':[], 'to':[]}\n",
    "for n in g.nodes():\n",
    "    for nbor in g.neighbors(n): _lu_['fm'].append(n), _lu_['to'].append(nbor)\n",
    "df        = pl.DataFrame(_lu_)\n",
    "_to_fix_  = {'node_0_5', 'node_7_4', 'node_8_6', 'node_5_8'}\n",
    "\n",
    "_relates_ = [('fm','to')]\n",
    "_colors_  = {n:'red' for n in _to_fix_}\n",
    "_psl_     = PolarsSpringLayout(g, normalize_coordinates=True)\n",
    "pos       = rt.treeMapGraphComponentPlacement(g, _psl_.results())\n",
    "new_pos   = copy.deepcopy(pos)\n",
    "for n in _to_fix_: new_pos[n] = (new_pos[n][0] + 100*(random.random()-0.5), new_pos[n][1] + 100*(random.random()-0.5))\n",
    "new_new_pos = copy.deepcopy(new_pos)\n",
    "new_new_pos = PolarsSpringLayout(g, pos=new_new_pos, static_nodes=set(g.nodes()) - _to_fix_, normalize_coordinates=True).results()\n",
    "params      = {'w':384, 'h':384, 'node_color':_colors_}\n",
    "rt.tile([rt.link(df, _relates_, pos,         **params),\n",
    "         rt.link(df, _relates_, new_pos,     **params),\n",
    "         rt.link(df, _relates_, new_new_pos, **params)], spacer=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acdfe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# So... maybe it's possible to rescale the graph based on the expected distances\n",
    "# ... in this case (mesh graph), all edges should be 1.0 ... so... how to take\n",
    "# ... a random set of positions & then rescale them?\n",
    "#\n",
    "_d_sum_, _d_samples_, _rms_sum_ = 0.0, 0, 0.0\n",
    "for n in g.nodes():\n",
    "    for nbor in g.neighbors(n):\n",
    "        _w_                  =  g[n][nbor]['weight']\n",
    "        _xy_n_, _xy_nbor_    =  pos[n], pos[nbor]\n",
    "        _d_                  =  rt.segmentLength((_xy_n_, _xy_nbor_))\n",
    "        _w_diff_             =  _w_ - _d_\n",
    "        _rms_sum_            += _w_diff_**2\n",
    "        _d_sum_, _d_samples_ = _d_sum_ + _d_, _d_samples_ + 1\n",
    "print(_d_sum_, _d_samples_, _d_sum_ / _d_samples_) # 359.24853900508407 288 1.2473907604343197 -- example from the mesh graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219b4fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Grid Search Version of This Optimization\n",
    "#\n",
    "_lu_ = {'x_scale':[], 'y_scale':[], 'rms':[]}\n",
    "_x_inc_, _y_inc_ = 2.0, 2.0\n",
    "_x_scale_        = 0.1\n",
    "while _x_scale_ < 100.0:\n",
    "    _y_scale_ = 1.0\n",
    "    while _y_scale_ < 100.0:\n",
    "        _rms_ = _psl_.rootMeanSquareError(_x_scale_, _y_scale_)\n",
    "        _lu_['x_scale'].append(_x_scale_), _lu_['y_scale'].append(_y_scale_), _lu_['rms'].append(_rms_)\n",
    "        _y_scale_ += _y_inc_\n",
    "    _x_scale_ += _x_inc_\n",
    "\n",
    "rt.tile([rt.xy(pl.DataFrame(_lu_), x_field='x_scale', y_field='rms', line_groupby_field='y_scale', color_by='y_scale', dot_size=None),\n",
    "         rt.xy(pl.DataFrame(_lu_), x_field='y_scale', y_field='rms', line_groupby_field='x_scale', color_by='x_scale', dot_size=None)], spacer=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c636df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weak_parabolic_bottom import WeakParabolicBottom\n",
    "def _fn_(x):\n",
    "    return _psl_.rootMeanSquareError(x, 1.0)\n",
    "_wpb_ = WeakParabolicBottom(_fn_)\n",
    "for _xy_ in _wpb_.xys:\n",
    "    print(_xy_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3fb299",
   "metadata": {},
   "outputs": [],
   "source": [
    "_wpb_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8be8eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
