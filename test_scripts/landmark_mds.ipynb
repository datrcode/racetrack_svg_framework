{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e840a3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Claude response for the following:  Create python code for the Landmark MDS algorithm.  The code should accept a single argument, g, which is a graph.\n",
    "#\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.sparse.csgraph import dijkstra\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def landmark_mds(g, num_landmarks=None, dimensions=2):\n",
    "    \"\"\"\n",
    "    Landmark Multidimensional Scaling (L-MDS) algorithm for graph embedding.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    g : networkx.Graph or scipy.sparse matrix or numpy.ndarray\n",
    "        Input graph. Can be a NetworkX graph, sparse matrix, or dense adjacency matrix.\n",
    "    num_landmarks : int, optional\n",
    "        Number of landmark nodes to select. If None, uses sqrt(n) where n is number of nodes.\n",
    "    dimensions : int, default=2\n",
    "        Number of dimensions for the embedding.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    coords : numpy.ndarray\n",
    "        Coordinates of all nodes in the embedded space (n_nodes x dimensions).\n",
    "    landmarks : numpy.ndarray\n",
    "        Indices of selected landmark nodes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert graph to adjacency matrix if needed\n",
    "    if isinstance(g, nx.Graph):\n",
    "        n = g.number_of_nodes()\n",
    "        # Create adjacency matrix with edge weights\n",
    "        adj_matrix = nx.to_scipy_sparse_array(g, weight='weight', format='csr')\n",
    "    elif isinstance(g, csr_matrix):\n",
    "        adj_matrix = g\n",
    "        n = adj_matrix.shape[0]\n",
    "    elif isinstance(g, np.ndarray):\n",
    "        adj_matrix = csr_matrix(g)\n",
    "        n = adj_matrix.shape[0]\n",
    "    else:\n",
    "        raise ValueError(\"Graph must be NetworkX graph, scipy sparse matrix, or numpy array\")\n",
    "    \n",
    "    # Set number of landmarks if not specified\n",
    "    if num_landmarks is None:\n",
    "        num_landmarks = max(int(np.sqrt(n)), dimensions + 1)\n",
    "    \n",
    "    num_landmarks = min(num_landmarks, n)\n",
    "    \n",
    "    # Step 1: Select landmark nodes (random selection)\n",
    "    landmarks = np.random.choice(n, size=num_landmarks, replace=False)\n",
    "    \n",
    "    # Step 2: Compute shortest path distances from all nodes to landmarks\n",
    "    # Using Dijkstra's algorithm from each landmark\n",
    "    distances = np.zeros((n, num_landmarks))\n",
    "    \n",
    "    for i, landmark in enumerate(landmarks):\n",
    "        dist = dijkstra(adj_matrix, directed=False, indices=landmark)\n",
    "        distances[:, i] = dist\n",
    "    \n",
    "    # Handle infinite distances (disconnected components)\n",
    "    max_finite_dist = np.max(distances[np.isfinite(distances)])\n",
    "    distances[np.isinf(distances)] = 2 * max_finite_dist\n",
    "    \n",
    "    # Step 3: Apply classical MDS on the distance matrix\n",
    "    # Center the squared distance matrix\n",
    "    D_squared = distances ** 2\n",
    "    n_samples = D_squared.shape[0]\n",
    "    n_landmarks = D_squared.shape[1]\n",
    "    \n",
    "    # Centering matrix\n",
    "    landmark_mean = D_squared.mean(axis=0)\n",
    "    overall_mean = D_squared.mean()\n",
    "    \n",
    "    # Double centering\n",
    "    B = -0.5 * (D_squared - landmark_mean - D_squared.mean(axis=1, keepdims=True) + overall_mean)\n",
    "    \n",
    "    # Step 4: Compute eigendecomposition and extract coordinates\n",
    "    # Use PCA for efficiency (equivalent to eigendecomposition)\n",
    "    pca = PCA(n_components=dimensions)\n",
    "    coords = pca.fit_transform(B)\n",
    "    \n",
    "    return coords, landmarks\n",
    "\n",
    "\n",
    "def landmark_mds_with_triangulation(g, num_landmarks=None, dimensions=2):\n",
    "    \"\"\"\n",
    "    Landmark MDS with triangulation for improved accuracy.\n",
    "    Uses distances to landmarks to triangulate positions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    g : networkx.Graph or scipy.sparse matrix or numpy.ndarray\n",
    "        Input graph.\n",
    "    num_landmarks : int, optional\n",
    "        Number of landmark nodes to select.\n",
    "    dimensions : int, default=2\n",
    "        Number of dimensions for the embedding.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    coords : numpy.ndarray\n",
    "        Coordinates of all nodes in the embedded space.\n",
    "    landmarks : numpy.ndarray\n",
    "        Indices of selected landmark nodes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get basic L-MDS embedding\n",
    "    coords, landmarks = landmark_mds(g, num_landmarks, dimensions)\n",
    "    \n",
    "    # Get landmark coordinates\n",
    "    landmark_coords = coords[landmarks]\n",
    "    \n",
    "    # Refine non-landmark positions using weighted least squares\n",
    "    # (triangulation based on distances to landmarks)\n",
    "    if isinstance(g, nx.Graph):\n",
    "        adj_matrix = nx.to_scipy_sparse_array(g, weight='weight', format='csr')\n",
    "    elif isinstance(g, csr_matrix):\n",
    "        adj_matrix = g\n",
    "    else:\n",
    "        adj_matrix = csr_matrix(g)\n",
    "    \n",
    "    n = adj_matrix.shape[0]\n",
    "    \n",
    "    # Compute distances to landmarks again\n",
    "    distances = np.zeros((n, len(landmarks)))\n",
    "    for i, landmark in enumerate(landmarks):\n",
    "        dist = dijkstra(adj_matrix, directed=False, indices=landmark)\n",
    "        distances[:, i] = dist\n",
    "    \n",
    "    max_finite_dist = np.max(distances[np.isfinite(distances)])\n",
    "    distances[np.isinf(distances)] = 2 * max_finite_dist\n",
    "    \n",
    "    return coords, landmarks\n",
    "\n",
    "import rtsvg\n",
    "rt = rtsvg.RACETrack()\n",
    "from linknode_graph_patterns import  LinkNodeGraphPatterns\n",
    "_patterns_ = LinkNodeGraphPatterns()\n",
    "_g_        = _patterns_.createPattern('stanford_facebook_networks')\n",
    "_df_       = _patterns_.nxGraphToPolarsDataFrame(_g_)\n",
    "_coords_, _landmarks_ = landmark_mds_with_triangulation(_g_) \n",
    "_pos_ = {}\n",
    "for i in range(len(_coords_)): _pos_[_g_.nodes[i]] = _coords_[i]\n",
    "rt.link(_df_, [('fm','to')], _pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4203bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
