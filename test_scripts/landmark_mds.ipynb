{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e840a3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Claude response for the following:  Create python code for the Landmark MDS algorithm.  The code should accept a single argument, g, which is a graph.\n",
    "# ... and then several iterations of changes to make it work...\n",
    "#\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.sparse.csgraph import dijkstra\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "class LandmarkMDSLayout(object):\n",
    "    def __init__(self, g, num_landmarks=None, dimensions=2):\n",
    "        \"\"\"\n",
    "        Landmark Multidimensional Scaling (L-MDS) algorithm for graph embedding.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        g : networkx.Graph or scipy.sparse matrix or numpy.ndarray\n",
    "            Input graph. Can be a NetworkX graph, sparse matrix, or dense adjacency matrix.\n",
    "        num_landmarks : int, optional\n",
    "            Number of landmark nodes to select. If None, uses sqrt(n) where n is number of nodes.\n",
    "        dimensions : int, default=2\n",
    "            Number of dimensions for the embedding.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Convert graph to adjacency matrix if needed\n",
    "        if isinstance(g, nx.Graph):\n",
    "            n = g.number_of_nodes()\n",
    "            # Create adjacency matrix with edge weights\n",
    "            adj_matrix = nx.to_scipy_sparse_array(g, weight='weight', format='csr')\n",
    "        elif isinstance(g, csr_matrix):\n",
    "            adj_matrix = g\n",
    "            n = adj_matrix.shape[0]\n",
    "        elif isinstance(g, np.ndarray):\n",
    "            adj_matrix = csr_matrix(g)\n",
    "            n = adj_matrix.shape[0]\n",
    "        else:\n",
    "            raise ValueError(\"Graph must be NetworkX graph, scipy sparse matrix, or numpy array\")\n",
    "        \n",
    "        # Set number of landmarks if not specified\n",
    "        if num_landmarks is None:\n",
    "            num_landmarks = max(int(np.sqrt(n)), dimensions + 1)\n",
    "        \n",
    "        num_landmarks = min(num_landmarks, n)\n",
    "        \n",
    "        # Step 1: Select landmark nodes (random selection)\n",
    "        landmarks = np.random.choice(n, size=num_landmarks, replace=False)\n",
    "        \n",
    "        # Step 2: Compute shortest path distances from all nodes to landmarks\n",
    "        # Using Dijkstra's algorithm from each landmark\n",
    "        distances = np.zeros((n, num_landmarks))\n",
    "        \n",
    "        for i, landmark in enumerate(landmarks):\n",
    "            dist = dijkstra(adj_matrix, directed=False, indices=landmark)\n",
    "            distances[:, i] = dist\n",
    "        \n",
    "        # Handle infinite distances (disconnected components)\n",
    "        max_finite_dist = np.max(distances[np.isfinite(distances)])\n",
    "        distances[np.isinf(distances)] = 2 * max_finite_dist\n",
    "        \n",
    "        # Step 3: Apply classical MDS on the distance matrix\n",
    "        # Center the squared distance matrix\n",
    "        D_squared = distances ** 2\n",
    "        n_samples = D_squared.shape[0]\n",
    "        n_landmarks = D_squared.shape[1]\n",
    "        \n",
    "        # Centering matrix\n",
    "        landmark_mean = D_squared.mean(axis=0)\n",
    "        overall_mean = D_squared.mean()\n",
    "        \n",
    "        # Double centering\n",
    "        B = -0.5 * (D_squared - landmark_mean - D_squared.mean(axis=1, keepdims=True) + overall_mean)\n",
    "        \n",
    "        # Step 4: Compute eigendecomposition and extract coordinates\n",
    "        # Use PCA for efficiency (equivalent to eigendecomposition)\n",
    "        pca = PCA(n_components=dimensions)\n",
    "        coords = pca.fit_transform(B)\n",
    "        \n",
    "        # Create node mapping for NetworkX graphs\n",
    "        node_mapping = None\n",
    "        if isinstance(g, nx.Graph):\n",
    "            node_mapping = list(g.nodes())\n",
    "            \n",
    "        # Get landmark coordinates\n",
    "        landmark_coords = coords[landmarks]\n",
    "        \n",
    "        # Refine non-landmark positions using weighted least squares\n",
    "        # (triangulation based on distances to landmarks)\n",
    "        if isinstance(g, nx.Graph):\n",
    "            adj_matrix = nx.to_scipy_sparse_array(g, weight='weight', format='csr')\n",
    "        elif isinstance(g, csr_matrix):\n",
    "            adj_matrix = g\n",
    "        else:\n",
    "            adj_matrix = csr_matrix(g)\n",
    "        \n",
    "        n = adj_matrix.shape[0]\n",
    "        \n",
    "        # Compute distances to landmarks again\n",
    "        distances = np.zeros((n, len(landmarks)))\n",
    "        for i, landmark in enumerate(landmarks):\n",
    "            dist = dijkstra(adj_matrix, directed=False, indices=landmark)\n",
    "            distances[:, i] = dist\n",
    "        \n",
    "        max_finite_dist = np.max(distances[np.isfinite(distances)])\n",
    "        distances[np.isinf(distances)] = 2 * max_finite_dist\n",
    "\n",
    "        self.coords, self.landmarks, self.node_mapping = coords, landmarks, node_mapping\n",
    "    \n",
    "    def results(self):\n",
    "        _pos_ = {}\n",
    "        for i in range(len(self.coords)): _pos_[self.node_mapping[i]] = self.coords[i]\n",
    "        return _pos_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4203bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import rtsvg\n",
    "rt = rtsvg.RACETrack()\n",
    "from linknode_graph_patterns import  LinkNodeGraphPatterns\n",
    "_patterns_ = LinkNodeGraphPatterns()\n",
    "_g_        = _patterns_.createPattern('stanford_facebook_networks')\n",
    "_df_       = _patterns_.nxGraphToPolarsDataFrame(_g_)\n",
    "\n",
    "# Create the layout & fill in the pos dictionary\n",
    "t0 = time.time()\n",
    "_pos_lmds_ = LandmarkMDSLayout(_g_).results()\n",
    "t1 = time.time()\n",
    "_pos_pfdl_ = rtsvg.PolarsForceDirectedLayout(_g_).results()\n",
    "t2 = time.time()\n",
    "\n",
    "print(f\"LMDs: {(t1-t0):.2f} | PFDL: {(t2-t1):.2f}\") # LMDs: 0.17 | PFDL: 16.10\n",
    "\n",
    "# Color the nodes\n",
    "_node_colors_ = {}\n",
    "community_i   = 0\n",
    "for _community_ in nx.community.louvain_communities(_g_):\n",
    "    community_i += 1\n",
    "    for _node_ in _community_: _node_colors_[_node_] = rt.co_mgr.getColor(community_i)\n",
    "\n",
    "# Display it\n",
    "_params_ = {'df':_df_, 'relationships':[('fm','to')], 'node_color':_node_colors_, 'w':512, 'h':512}\n",
    "rt.tile([rt.link(pos=_pos_lmds_, **_params_), rt.link(pos=_pos_pfdl_, **_params_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e09d306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
