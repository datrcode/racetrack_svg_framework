{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e840a3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.sparse.csgraph import dijkstra\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#\n",
    "# Implementation of Landmark MDS\n",
    "#\n",
    "# V. de Silva and J. Tenenbaum. Global versus local methods in nonlinear dimensionality reduction. \n",
    "# In Proc. NIPS, pages 721–728, 2003.\n",
    "#\n",
    "# Generated by Claude Sonnet 4.5 (2025-10-23)\n",
    "#\n",
    "class LandmarkMDSLayout(object):\n",
    "    def __init__(self, g, num_landmarks=None, dimensions=2):\n",
    "        \"\"\"\n",
    "        Landmark Multidimensional Scaling (L-MDS) algorithm for graph embedding.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        g : networkx.Graph or scipy.sparse matrix or numpy.ndarray\n",
    "            Input graph. Can be a NetworkX graph, sparse matrix, or dense adjacency matrix.\n",
    "        num_landmarks : int, optional\n",
    "            Number of landmark nodes to select. If None, uses sqrt(n) where n is number of nodes.\n",
    "        dimensions : int, default=2\n",
    "            Number of dimensions for the embedding.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Convert graph to adjacency matrix if needed\n",
    "        if isinstance(g, nx.Graph):\n",
    "            n = g.number_of_nodes()\n",
    "            # Create adjacency matrix with edge weights\n",
    "            adj_matrix = nx.to_scipy_sparse_array(g, weight='weight', format='csr')\n",
    "        elif isinstance(g, csr_matrix):\n",
    "            adj_matrix = g\n",
    "            n = adj_matrix.shape[0]\n",
    "        elif isinstance(g, np.ndarray):\n",
    "            adj_matrix = csr_matrix(g)\n",
    "            n = adj_matrix.shape[0]\n",
    "        else:\n",
    "            raise ValueError(\"Graph must be NetworkX graph, scipy sparse matrix, or numpy array\")\n",
    "        \n",
    "        # Set number of landmarks if not specified\n",
    "        if num_landmarks is None:\n",
    "            num_landmarks = max(int(np.sqrt(n)), dimensions + 1)\n",
    "        \n",
    "        num_landmarks = min(num_landmarks, n)\n",
    "        \n",
    "        # Step 1: Select landmark nodes (random selection)\n",
    "        landmarks = np.random.choice(n, size=num_landmarks, replace=False)\n",
    "        \n",
    "        # Step 2: Compute shortest path distances from all nodes to landmarks\n",
    "        # Using Dijkstra's algorithm from each landmark\n",
    "        distances = np.zeros((n, num_landmarks))\n",
    "        \n",
    "        for i, landmark in enumerate(landmarks):\n",
    "            dist = dijkstra(adj_matrix, directed=False, indices=landmark)\n",
    "            distances[:, i] = dist\n",
    "        \n",
    "        # Handle infinite distances (disconnected components)\n",
    "        max_finite_dist = np.max(distances[np.isfinite(distances)])\n",
    "        distances[np.isinf(distances)] = 2 * max_finite_dist\n",
    "        \n",
    "        # Step 3: Apply classical MDS on the distance matrix\n",
    "        # Center the squared distance matrix\n",
    "        D_squared = distances ** 2\n",
    "        n_samples = D_squared.shape[0]\n",
    "        n_landmarks = D_squared.shape[1]\n",
    "        \n",
    "        # Centering matrix\n",
    "        landmark_mean = D_squared.mean(axis=0)\n",
    "        overall_mean = D_squared.mean()\n",
    "        \n",
    "        # Double centering\n",
    "        B = -0.5 * (D_squared - landmark_mean - D_squared.mean(axis=1, keepdims=True) + overall_mean)\n",
    "        \n",
    "        # Step 4: Compute eigendecomposition and extract coordinates\n",
    "        # Use PCA for efficiency (equivalent to eigendecomposition)\n",
    "        pca = PCA(n_components=dimensions)\n",
    "        coords = pca.fit_transform(B)\n",
    "        \n",
    "        # Create node mapping for NetworkX graphs\n",
    "        node_mapping = None\n",
    "        if isinstance(g, nx.Graph):\n",
    "            node_mapping = list(g.nodes())\n",
    "            \n",
    "        # Get landmark coordinates\n",
    "        landmark_coords = coords[landmarks]\n",
    "        \n",
    "        # Refine non-landmark positions using weighted least squares\n",
    "        # (triangulation based on distances to landmarks)\n",
    "        if isinstance(g, nx.Graph):\n",
    "            adj_matrix = nx.to_scipy_sparse_array(g, weight='weight', format='csr')\n",
    "        elif isinstance(g, csr_matrix):\n",
    "            adj_matrix = g\n",
    "        else:\n",
    "            adj_matrix = csr_matrix(g)\n",
    "        \n",
    "        n = adj_matrix.shape[0]\n",
    "        \n",
    "        # Compute distances to landmarks again\n",
    "        distances = np.zeros((n, len(landmarks)))\n",
    "        for i, landmark in enumerate(landmarks):\n",
    "            dist = dijkstra(adj_matrix, directed=False, indices=landmark)\n",
    "            distances[:, i] = dist\n",
    "        \n",
    "        max_finite_dist = np.max(distances[np.isfinite(distances)])\n",
    "        distances[np.isinf(distances)] = 2 * max_finite_dist\n",
    "\n",
    "        self.coords, self.landmarks, self.node_mapping = coords, landmarks, node_mapping\n",
    "    \n",
    "    def results(self):\n",
    "        _pos_ = {}\n",
    "        for i in range(len(self.coords)): _pos_[self.node_mapping[i]] = self.coords[i]\n",
    "        return _pos_\n",
    "\n",
    "#\n",
    "# Implementation of PivotMDS\n",
    "#\n",
    "# U. Brandes and C. Pich. Eigensolver methods for progressive multidimensional scaling of large data. \n",
    "# In Proceedings 14th Symposium on Graph Drawing (GD), pages 42–53, 2006.\n",
    "#\n",
    "# Generated by Claude Sonnet 4.5 (2025-10-23)\n",
    "#\n",
    "class PivotMDSLayout(object):\n",
    "    def __init__(self, g, num_pivots=None, dimensions=2):\n",
    "        \"\"\"\n",
    "        Pivot MDS with MaxMin pivot selection strategy.\n",
    "        \n",
    "        Instead of random selection, pivots are chosen iteratively to maximize\n",
    "        the minimum distance to already selected pivots, providing better coverage.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        g : networkx.Graph or scipy.sparse matrix or numpy.ndarray\n",
    "            Input graph.\n",
    "        num_pivots : int, optional\n",
    "            Number of pivot nodes to select.\n",
    "        dimensions : int, default=2\n",
    "            Number of dimensions for the final embedding.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        coords : numpy.ndarray\n",
    "            Coordinates of all nodes in the embedded space.\n",
    "        pivots : numpy.ndarray\n",
    "            Indices of selected pivot nodes.\n",
    "        node_mapping : list or None\n",
    "            List mapping array indices to original node identifiers.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Convert graph to adjacency matrix if needed\n",
    "        if isinstance(g, nx.Graph):\n",
    "            n = g.number_of_nodes()\n",
    "            node_mapping = list(g.nodes())\n",
    "            adj_matrix = nx.to_scipy_sparse_array(g, weight='weight', format='csr')\n",
    "        elif isinstance(g, csr_matrix):\n",
    "            adj_matrix = g\n",
    "            n = adj_matrix.shape[0]\n",
    "            node_mapping = None\n",
    "        elif isinstance(g, np.ndarray):\n",
    "            adj_matrix = csr_matrix(g)\n",
    "            n = adj_matrix.shape[0]\n",
    "            node_mapping = None\n",
    "        else:\n",
    "            raise ValueError(\"Graph must be NetworkX graph, scipy sparse matrix, or numpy array\")\n",
    "        \n",
    "        # Set number of pivots if not specified\n",
    "        if num_pivots is None:\n",
    "            num_pivots = max(int(np.sqrt(n)), dimensions + 1)\n",
    "        \n",
    "        num_pivots = min(num_pivots, n)\n",
    "        \n",
    "        # Step 1: Select pivots using MaxMin strategy\n",
    "        pivots = []\n",
    "        \n",
    "        # Select first pivot randomly\n",
    "        first_pivot = np.random.randint(0, n)\n",
    "        pivots.append(first_pivot)\n",
    "        \n",
    "        # Initialize minimum distances to first pivot\n",
    "        min_distances = dijkstra(adj_matrix, directed=False, indices=first_pivot)\n",
    "        min_distances[np.isinf(min_distances)] = 0\n",
    "        \n",
    "        # Select remaining pivots\n",
    "        for _ in range(num_pivots - 1):\n",
    "            # Select node with maximum minimum distance to existing pivots\n",
    "            next_pivot = np.argmax(min_distances)\n",
    "            pivots.append(next_pivot)\n",
    "            \n",
    "            # Update minimum distances\n",
    "            new_distances = dijkstra(adj_matrix, directed=False, indices=next_pivot)\n",
    "            new_distances[np.isinf(new_distances)] = 0\n",
    "            min_distances = np.minimum(min_distances, new_distances)\n",
    "        \n",
    "        pivots = np.array(pivots)\n",
    "        \n",
    "        # Step 2: Compute distances from all nodes to selected pivots\n",
    "        distances = np.zeros((n, num_pivots))\n",
    "        \n",
    "        for i, pivot in enumerate(pivots):\n",
    "            dist = dijkstra(adj_matrix, directed=False, indices=pivot)\n",
    "            distances[:, i] = dist\n",
    "        \n",
    "        # Handle infinite distances\n",
    "        max_finite_dist = np.max(distances[np.isfinite(distances)])\n",
    "        distances[np.isinf(distances)] = 2 * max_finite_dist\n",
    "        \n",
    "        # Step 3: Center and reduce dimensions\n",
    "        col_means = distances.mean(axis=0)\n",
    "        distances_centered = distances - col_means\n",
    "        \n",
    "        # Step 4: SVD for dimensionality reduction\n",
    "        if num_pivots > dimensions:\n",
    "            U, S, Vt = np.linalg.svd(distances_centered, full_matrices=False)\n",
    "            coords = U[:, :dimensions] * S[:dimensions]\n",
    "        else:\n",
    "            coords = distances_centered\n",
    "        \n",
    "        self.coords, self.pivots, self.node_mapping = coords, pivots, node_mapping\n",
    "\n",
    "    def results(self):\n",
    "        _pos_ = {}\n",
    "        for i in range(len(self.coords)): _pos_[self.node_mapping[i]] = self.coords[i]\n",
    "        return _pos_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4203bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import rtsvg\n",
    "rt = rtsvg.RACETrack()\n",
    "from linknode_graph_patterns import  LinkNodeGraphPatterns\n",
    "_patterns_ = LinkNodeGraphPatterns()\n",
    "_g_        = _patterns_.createPattern('stanford_facebook_networks')\n",
    "_df_       = _patterns_.nxGraphToPolarsDataFrame(_g_)\n",
    "\n",
    "# Create the layout & fill in the pos dictionary\n",
    "t0 = time.time()\n",
    "_pos_lmds_ = LandmarkMDSLayout(_g_).results()\n",
    "t1 = time.time()\n",
    "_pos_pmds_ = PivotMDSLayout(_g_).results()\n",
    "t2 = time.time()\n",
    "\n",
    "# previous (compared to the force directed implementation) LMDs: 0.17 | PFDL: 16.10\n",
    "print(f\"LMDs: {(t1-t0):.2f} | PMDS: {(t2-t1):.2f}\") # LMDs: 0.08 | PMDS: 0.16\n",
    "\n",
    "# Color the nodes\n",
    "_node_colors_ = {}\n",
    "community_i   = 0\n",
    "for _community_ in nx.community.louvain_communities(_g_):\n",
    "    community_i += 1\n",
    "    for _node_ in _community_: _node_colors_[_node_] = rt.co_mgr.getColor(community_i)\n",
    "\n",
    "# Display it\n",
    "_params_ = {'df':_df_, 'relationships':[('fm','to')], 'node_color':_node_colors_, 'w':512, 'h':512}\n",
    "rt.tile([rt.link(pos=_pos_lmds_, **_params_), rt.link(pos=_pos_pmds_, **_params_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abf2728",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
