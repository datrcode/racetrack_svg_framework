{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2bf2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import networkx as nx\n",
    "from math import sqrt\n",
    "import time\n",
    "import random\n",
    "import rtsvg\n",
    "rt = rtsvg.RACETrack()\n",
    "# Create a graph\n",
    "from linknode_graph_patterns import LinkNodeGraphPatterns\n",
    "_patterns_ = LinkNodeGraphPatterns()\n",
    "g          = _patterns_.createPattern('mesh')\n",
    "# Create the dataframe version of the graph\n",
    "_lu_ = {'fm':[], 'to':[]}\n",
    "for edge in g.edges: _lu_['fm'].append(edge[0]), _lu_['to'].append(edge[1])\n",
    "df = pl.DataFrame(_lu_)\n",
    "'''\n",
    "_base_network_ = '0'\n",
    "_base_dir_     = '../../data/stanford/facebook/'\n",
    "_layout_file_  = _base_dir_ + _base_network_ + '.layout.parquet'\n",
    "_edges_ = open(_base_dir_ + _base_network_ + '.edges', 'rt').read()\n",
    "_lu_ = {'fm':[], 'to':[]}\n",
    "for _edge_ in _edges_.split('\\n'):\n",
    "    if _edge_ == '': continue\n",
    "    _lu_['fm'].append(_edge_.split(' ')[0])\n",
    "    _lu_['to'].append(_edge_.split(' ')[1])\n",
    "df = pl.DataFrame(_lu_)\n",
    "g  = rt.createNetworkXGraph(df, [('fm', 'to')])\n",
    "len(df), len(set(df['fm'])), len(set(df['to'])), len(set(df['fm']) | set(df['to']))\n",
    "'''\n",
    "print(f'edges: {len(g.edges)} | nodes: {len(g.nodes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c56ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# \"Graph Drawing by Force-directed Placement\"\n",
    "# Fruchterman & Reingold\n",
    "# Software -- Practice and Experience, Vol. 21 (1 1), 1129-1164 (November 1991)\n",
    "#\n",
    "# Figure 1 (Force-directed Placement)\n",
    "# - with the optimization to only consider vertices w/in 2*k of the vertex for repulsion\n",
    "#\n",
    "pos_history = {}\n",
    "for _node_ in g.nodes: pos_history[_node_] = []\n",
    "\n",
    "t    = 4.0\n",
    "W, H = 256, 256\n",
    "pos  = {}\n",
    "for _node_ in g.nodes(): pos[_node_] = random.random()*W, random.random()*H\n",
    "area = W*H\n",
    "C   = 0.2 # paper says that C is found experimentally...\n",
    "k   = C*sqrt(area/len(g.nodes()))\n",
    "def f_a(z): return  z**2 / k             # pseudocode says \"x\" vs \"z\" ... paper comments say \"z\"\n",
    "def f_r(z): return  ((k**2)/z)*(2*k - z) # updated formula when only using near neighbors for repulsion\n",
    "\n",
    "t0 = time.time()\n",
    "_iterations_ = 2*len(g.nodes())\n",
    "for i in range(_iterations_):\n",
    "    for _node_ in g.nodes: pos_history[_node_].append(pos[_node_])\n",
    "    disp = {}\n",
    "    # calculate repulsive forces\n",
    "    for v in g.nodes():\n",
    "        disp[v] = 0.0, 0.0\n",
    "        for u in g.nodes():\n",
    "            if u == v or g.has_edge(u, v): continue\n",
    "            _diff_     = pos[v][0] - pos[u][0], pos[v][1] - pos[u][1]\n",
    "            _diff_len_ = max(sqrt(_diff_[0]**2 + _diff_[1]**2), 0.001)\n",
    "            if _diff_len_ > 2*k: continue\n",
    "            disp[v]    = disp[v][0] + (_diff_[0]/_diff_len_) * f_r(_diff_len_), disp[v][1] + (_diff_[1]/_diff_len_) * f_r(_diff_len_)\n",
    "    # calculate the attractive forces\n",
    "    for e in g.edges():\n",
    "        e_v, e_u, w = e[0], e[1], 1 if 'weight' not in g[e[0]][e[1]] else g[e[0]][e[1]]['weight']\n",
    "        _diff_     = pos[e_v][0] - pos[e_u][0], pos[e_v][1] - pos[e_u][1]\n",
    "        _diff_len_ = max(sqrt(_diff_[0]**2 + _diff_[1]**2), 0.001)\n",
    "        disp[e_v]  = disp[e_v][0] - (_diff_[0]/(_diff_len_*w)) * f_a(_diff_len_), disp[e_v][1] - (_diff_[1]/(_diff_len_*w)) * f_a(_diff_len_)\n",
    "        disp[e_u]  = disp[e_u][0] + (_diff_[0]/(_diff_len_*w)) * f_a(_diff_len_), disp[e_u][1] + (_diff_[1]/(_diff_len_*w)) * f_a(_diff_len_)\n",
    "    # limit the maximum displacement to the temperature t\n",
    "    # ... and then prevent from being displaced outside frame\n",
    "    for v in g.nodes():\n",
    "        disp_len   = max(sqrt(disp[v][0]**2 + disp[v][1]**2), 0.001)\n",
    "        xmag, ymag = t if abs(disp[v][0]) > t else disp[v][0], t if abs(disp[v][1]) > t else disp[v][1]\n",
    "        pos[v] = pos[v][0] + (disp[v][0]/disp_len)*xmag, pos[v][1] + (disp[v][1]/disp_len)*ymag\n",
    "    t *= 0.98 # t = cool(t)\n",
    "\n",
    "    # Rescale th positions to fit the frame\n",
    "    # ... the paper has a several proposals for how to keep all the vertices in the frame\n",
    "    # ... kindof unsure if this is necessary or not\n",
    "    x0, y0, x1, y1 = pos[v][0], pos[v][1], pos[v][0], pos[v][1]\n",
    "    for _node_ in pos.keys():\n",
    "        x0, y0 = min(x0, pos[_node_][0]), min(y0, pos[_node_][1])\n",
    "        x1, y1 = max(x1, pos[_node_][0]), max(y1, pos[_node_][1])\n",
    "    # for _node_ in pos.keys(): pos[_node_] = W*(pos[_node_][0] - x0)/(x1-x0), H*(pos[_node_][1] - y0)/(y1-y0)\n",
    "\n",
    "for _node_ in g.nodes: pos_history[_node_].append(pos[_node_])\n",
    "\n",
    "x0, y0, x1, y1 = pos[v][0], pos[v][1], pos[v][0], pos[v][1]\n",
    "for k in pos_history.keys():\n",
    "    x0, y0 = min(x0, min(pos_history[k][0])), min(y0, min(pos_history[k][1]))\n",
    "    x1, y1 = max(x1, max(pos_history[k][0])), max(y1, max(pos_history[k][1]))\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "# Convert it to an animation\n",
    "_dur_ = '5s'\n",
    "svg = [f'<svg x=\"0\" y=\"0\" width=\"512\" height=\"512\" viewBox=\"{x0} {y0} {x1-x0} {y1-y0}\">']\n",
    "svg.append(f'<rect x=\"{x0}\" y=\"{y0}\"  width=\"{x1-x0}\" height=\"{y1-y0}\" fill=\"white\" />')\n",
    "for _edge_ in g.edges:\n",
    "    u, v = _edge_[0], _edge_[1]\n",
    "    svg.append(f'<line x1=\"{pos[u][0]}\" y1=\"{pos[u][1]}\" x2=\"{pos[v][0]}\" y2=\"{pos[v][1]}\" stroke=\"black\" stroke-width=\"0.2\">')\n",
    "    svg.append(f'<animate attributeName=\"x1\" values=\"{\";\".join([f\"{_pos_[0]}\" for _pos_ in pos_history[u]])}\" dur=\"{_dur_}\" repeatCount=\"indefinite\" />')\n",
    "    svg.append(f'<animate attributeName=\"y1\" values=\"{\";\".join([f\"{_pos_[1]}\" for _pos_ in pos_history[u]])}\" dur=\"{_dur_}\" repeatCount=\"indefinite\" />')\n",
    "    svg.append(f'<animate attributeName=\"x2\" values=\"{\";\".join([f\"{_pos_[0]}\" for _pos_ in pos_history[v]])}\" dur=\"{_dur_}\" repeatCount=\"indefinite\" />')\n",
    "    svg.append(f'<animate attributeName=\"y2\" values=\"{\";\".join([f\"{_pos_[1]}\" for _pos_ in pos_history[v]])}\" dur=\"{_dur_}\" repeatCount=\"indefinite\" />')\n",
    "    svg.append('</line>')\n",
    "for _node_ in g.nodes:\n",
    "    svg.append(f'<circle cx=\"{pos_history[_node_][0][0]}\" cy=\"{pos_history[_node_][0][1]}\" r=\"1.2\" fill=\"blue\">')\n",
    "    svg.append(f'<animate attributeName=\"cx\" values=\"{\";\".join([f\"{_pos_[0]}\" for _pos_ in pos_history[_node_]])}\" dur=\"{_dur_}\" repeatCount=\"indefinite\" />')\n",
    "    svg.append(f'<animate attributeName=\"cy\" values=\"{\";\".join([f\"{_pos_[1]}\" for _pos_ in pos_history[_node_]])}\" dur=\"{_dur_}\" repeatCount=\"indefinite\" />')\n",
    "    svg.append('</circle>')\n",
    "svg.append('</svg>')\n",
    "\n",
    "_lu_ = {'fm':[], 'to':[]}\n",
    "for edge in g.edges: _lu_['fm'].append(edge[0]), _lu_['to'].append(edge[1])\n",
    "df = pl.DataFrame(_lu_)\n",
    "#rt.tile([''.join(svg), rt.link(df, [('fm','to')],pos)], spacer=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6f5737",
   "metadata": {},
   "outputs": [],
   "source": [
    "t    = 4.0\n",
    "W, H = 256, 256\n",
    "area = W*H\n",
    "C   = 0.2 # paper says that C is found experimentally...\n",
    "k   = C*sqrt(area/len(g.nodes()))\n",
    "\n",
    "static_nodes = None\n",
    "\n",
    "# Distance DataFrame\n",
    "_lu_    = {'fm':[], 'to':[], 't':[]}\n",
    "for node in g.nodes:\n",
    "    for nbor in g.neighbors(node):\n",
    "        _w_ = g[node][nbor]['weight'] if 'weight' in g[node][nbor] else 1.0\n",
    "        _lu_['fm'].append(node), _lu_['to'].append(nbor), _lu_['t'].append(_w_)\n",
    "df_dist = pl.DataFrame(_lu_)\n",
    "\n",
    "# Positional DataFrame\n",
    "_lu_    = {'node':[], 'x':[], 'y':[], 's':[]}\n",
    "for node in g.nodes: \n",
    "    _lu_['node'].append(node)\n",
    "    if pos is not None and node in pos: _lu_['x'].append(pos[node][0]),      _lu_['y'].append(pos[node][1])\n",
    "    else:                               _lu_['x'].append(W*random.random()), _lu_['y'].append(H*random.random()) \n",
    "    if static_nodes is not None and node in static_nodes: _lu_['s'].append(True)\n",
    "    else:                                                 _lu_['s'].append(False)\n",
    "df_pos  = pl.DataFrame(_lu_)\n",
    "\n",
    "# Cross join of all of the nodes\n",
    "df_cross = df_pos.drop('s')\\\n",
    "                 .join(df_pos.drop('s'), how='cross') \\\n",
    "                 .filter(pl.col('node') != pl.col('node_right'))\n",
    "\n",
    "df_cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179307d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe describing one off tiles\n",
    "df_around = pl.DataFrame({'xi_offset':[-1,  0,  1, -1, 1, -1, 0, 1],\n",
    "                          'yi_offset':[-1, -1, -1,  0, 0,  1, 1, 1]})\n",
    "# Calculate the tile xi, yi based on the 2*k parameter\n",
    "_df_ = df_pos.with_columns(((pl.col('x') - pl.col('x').min())//(2 * k)).cast(pl.Int32).alias('xi'),\n",
    "                           ((pl.col('y') - pl.col('y').min())//(2 * k)).cast(pl.Int32).alias('yi'))\n",
    "_df_ = _df_.join(df_around, how='cross')\n",
    "# Determine which tiles a node needs\n",
    "_df_ = _df_.with_columns((pl.col('xi_offset')+pl.col('xi')).alias('xi_join'),\n",
    "                         (pl.col('yi_offset')+pl.col('yi')).alias('yi_join'))\n",
    "# Join those tiles in\n",
    "_df_ = _df_.join(_df_, left_on=['xi_join','yi_join'], right_on=['xi','yi']) # this removes node == node_right by default...\n",
    "# Remove all the fields related to tiles\n",
    "_df_ = _df_.drop(['s','xi','yi','xi_offset','yi_offset','xi_join','yi_join','s_right','xi_offset_right','yi_offset_right','xi_join_right','yi_join_right'])\n",
    "# Remove edges (these are not repulsed)\n",
    "_df_ = _df_.join(df_dist, left_on=['node','node_right'], right_on=['fm','to'], how='anti')\n",
    "# Calculate the distance squared\n",
    "_df_ = _df_.with_columns(((pl.col('x_right')-pl.col('x'))**2 + (pl.col('y_right')-pl.col('y'))**2).alias('d_squared'))\n",
    "# filter out the ones that are too far\n",
    "_df_ = _df_.filter(pl.col('d_squared') < (2*k)**2)\n",
    "_df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59b1677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
