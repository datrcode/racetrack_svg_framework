{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import random\n",
    "import rtsvg\n",
    "rt = rtsvg.RACETrack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# spreadLines() - attempt to implement this visualization\n",
    "#\n",
    "# Based on:\n",
    "#\n",
    "# @misc{kuo2024spreadlinevisualizingegocentricdynamic,\n",
    "#       title={SpreadLine: Visualizing Egocentric Dynamic Influence}, \n",
    "#       author={Yun-Hsin Kuo and Dongyu Liu and Kwan-Liu Ma},\n",
    "#       year={2024},\n",
    "#       eprint={2408.08992},\n",
    "#       archivePrefix={arXiv},\n",
    "#       primaryClass={cs.HC},\n",
    "#       url={https://arxiv.org/abs/2408.08992}, \n",
    "# }\n",
    "# \n",
    "def spreadLines(rt_self,\n",
    "                df,\n",
    "                relationships,\n",
    "                node_focus,\n",
    "                ts_field        = None,              # Will attempt to guess based on datatypes\n",
    "                ts_bins         = 'year_month_day',  # From rt.transforms\n",
    "                color_by        = None,\n",
    "                count_by        = None,\n",
    "                count_by_set    = False,\n",
    "                widget_id       = None,\n",
    "                w               = 1024,\n",
    "                h               = 512,\n",
    "                txt_h           = 12):\n",
    "    return SpreadLines(**locals())\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "class SpreadLines(object):\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    def __transformFields__(self):\n",
    "        # Gather up all of the fields that are going to be used\n",
    "        _all_columns_ = [self.ts_field]\n",
    "        if self.color_by is not None: _all_columns_.append(self.color_by)\n",
    "        if self.count_by is not None: _all_columns_.append(self.count_by)\n",
    "        for _relationship_ in self.relationships:\n",
    "            _fm_, _to_ = _relationship_[0], _relationship_[1]\n",
    "            if   type(_fm_) is str: _all_columns_.append(_fm_)\n",
    "            elif type(_fm_) is tuple:\n",
    "                for i in range(len(_fm_)): _all_columns_.append(_fm_[i])\n",
    "            if   type(_to_) is str: _all_columns_.append(_to_)\n",
    "            elif type(_to_) is tuple:\n",
    "                for i in range(len(_to_)): _all_columns_.append(_to_[i])\n",
    "        # Transform the fields\n",
    "        self.df, _new_columns_ = self.rt_self.transformFieldListAndDataFrame(self.df, _all_columns_)\n",
    "        # Remap them\n",
    "        col_i = 0\n",
    "        self.ts_field        = _new_columns_[col_i]\n",
    "        col_i += 1\n",
    "        if self.color_by is not None: \n",
    "            self.color_by = _new_columns_[col_i]\n",
    "            col_i += 1\n",
    "        if self.count_by is not None:\n",
    "            self.count_by = _new_columns_[col_i]\n",
    "            col_i += 1\n",
    "        _new_relationships_ = []\n",
    "        for _relationship_ in self.relationships:\n",
    "            _fm_, _to_ = _relationship_[0], _relationship_[1]\n",
    "            if   type(_fm_) is str: \n",
    "                _fm_ = _new_columns_[col_i]\n",
    "                col_i += 1\n",
    "            elif type(_fm_) is tuple:\n",
    "                for i in range(len(_fm_)): \n",
    "                    _fm_[i] = _new_columns_[col_i]\n",
    "                    col_i += 1\n",
    "            if   type(_to_) is str: \n",
    "                _to_ = _new_columns_[col_i]\n",
    "                col_i += 1\n",
    "            elif type(_to_) is tuple:\n",
    "                for i in range(len(_to_)): \n",
    "                    _to_[i] = _new_columns_[col_i]\n",
    "                    col_i += 1\n",
    "            _new_relationships_.append((_fm_, _to_))\n",
    "        self.relationships = _new_relationships_\n",
    "\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    def __init__(self, rt_self, **kwargs):\n",
    "        self.rt_self       = rt_self\n",
    "        self.df            = rt_self.copyDataFrame(kwargs['df'])\n",
    "        self.relationships = kwargs['relationships']\n",
    "        self.node_focus    = kwargs['node_focus']\n",
    "        self.ts_field      = self.rt_self.guessTimestampField(self.df) if kwargs['ts_field'] is None else kwargs['ts_field']\n",
    "        self.ts_bins       = kwargs['ts_bins']\n",
    "        self.color_by      = kwargs['color_by']\n",
    "        self.count_by      = kwargs['count_by']\n",
    "        self.count_by_set  = kwargs['count_by_set']\n",
    "        self.widget_id     = f'spreadlines_{random.randint(0,65535)}' if kwargs['widget_id'] is None else kwargs['widget_id']\n",
    "        self.w             = kwargs['w']\n",
    "        self.h             = kwargs['h']\n",
    "        self.txt_h         = kwargs['txt_h']\n",
    "\n",
    "        # Unwrap any fields\n",
    "        self.__transformFields__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv('../../data/2013_vast_challenge/mc3_netflow/nf/nf-chunk1.csv')\n",
    "df = rt.columnsAreTimestamps(df, 'parsedDate')\n",
    "df = df.rename({'TimeSeconds':                '_del1_',\n",
    "                'parsedDate':                 'timestamp',\n",
    "                'dateTimeStr':                '_del2_',\n",
    "                'ipLayerProtocol':            'pro',\n",
    "                'ipLayerProtocolCode':        '_del3_',\n",
    "                'firstSeenSrcIp':             'sip',\n",
    "                'firstSeenDestIp':            'dip',\n",
    "                'firstSeenSrcPort':           'spt',\n",
    "                'firstSeenDestPort':          'dpt',\n",
    "                'moreFragments':              '_del4_',\n",
    "                'contFragments':              '_del5_',\n",
    "                'durationSeconds':            'dur',\n",
    "                'firstSeenSrcPayloadBytes':   '_del6_',\n",
    "                'firstSeenDestPayloadBytes':  '_del7_',\n",
    "                'firstSeenSrcTotalBytes':     'soct',\n",
    "                'firstSeenDestTotalBytes':    'doct',\n",
    "                'firstSeenSrcPacketCount':    'spkt',\n",
    "                'firstSeenDestPacketCount':   'dpkt',\n",
    "                'recordForceOut':             '_del8_'})\n",
    "df = df.drop(['_del1_', '_del2_', '_del3_', '_del4_', '_del5_', '_del6_', '_del7_', '_del8_'])\n",
    "spreadLines(rt, df, [('sip', 'dip')], '172.30.0.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
